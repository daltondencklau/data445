{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe9e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_column', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## define bucket in which you are trying to reach\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'daltondencklau-data445-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## define csv file to read in the bucket\n",
    "file_key= 'College.csv'\n",
    "\n",
    "## syntax to allow us to read the file\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## reading the data file\n",
    "college = pd.read_csv(file_content_stream)\n",
    "college.head()\n",
    "\n",
    "## disabling the 'FutureWarning' warning message\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b61895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene Christian University</th>\n",
       "      <td>1</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adelphi University</th>\n",
       "      <td>1</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrian College</th>\n",
       "      <td>1</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agnes Scott College</th>\n",
       "      <td>1</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska Pacific University</th>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Private  Apps  Accept  Enroll  Top10perc  \\\n",
       "Abilene Christian University        1  1660    1232     721         23   \n",
       "Adelphi University                  1  2186    1924     512         16   \n",
       "Adrian College                      1  1428    1097     336         22   \n",
       "Agnes Scott College                 1   417     349     137         60   \n",
       "Alaska Pacific University           1   193     146      55         16   \n",
       "\n",
       "                              Top25perc  F.Undergrad  P.Undergrad  Outstate  \\\n",
       "Abilene Christian University         52         2885          537      7440   \n",
       "Adelphi University                   29         2683         1227     12280   \n",
       "Adrian College                       50         1036           99     11250   \n",
       "Agnes Scott College                  89          510           63     12960   \n",
       "Alaska Pacific University            44          249          869      7560   \n",
       "\n",
       "                              Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "Abilene Christian University        3300    450      2200   70        78   \n",
       "Adelphi University                  6450    750      1500   29        30   \n",
       "Adrian College                      3750    400      1165   53        66   \n",
       "Agnes Scott College                 5450    450       875   92        97   \n",
       "Alaska Pacific University           4120    800      1500   76        72   \n",
       "\n",
       "                              S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "Abilene Christian University       18.1           12    7041         60  \n",
       "Adelphi University                 12.2           16   10527         56  \n",
       "Adrian College                     12.9           30    8735         54  \n",
       "Agnes Scott College                 7.7           37   19016         59  \n",
       "Alaska Pacific University          11.9            2   10922         15  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Changing the variable 'Private' from a categorical to a numerical variable\n",
    "college['Private'] = np.where(college['Private'] == 'No', 0 ,1)\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad05aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining the input (x) and target (y) variables\n",
    "X = college[['Private', 'F.Undergrad', 'P.Undergrad', 'Outstate', 'Room.Board', 'Books', 'Personal', 'S.F.Ratio', 'Grad.Rate']]\n",
    "Y = college['Apps']\n",
    "## splitting the data into 80% trianing and 20% testing datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52f37f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transforming the input variables in the training and testing dataset to a 0-1 scale\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f39770",
   "metadata": {},
   "source": [
    "## building linear regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54b04d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitting the data to a linear regression model\n",
    "lm_md = LinearRegression().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ece14b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6575.50060966,  2617.99670683,   398.20370707,  4194.57374335,\n",
       "        4291.97053319,  4579.9400438 ,  2627.88870824,  4612.18466249,\n",
       "         327.10559673, 10197.02393099,  3833.04574956,  3126.35375777,\n",
       "         735.92240265,  1688.40043197,  3202.29339385,  4893.10823053,\n",
       "        3764.53910102,  7998.46566191,  1103.65831189,  1577.15603435,\n",
       "        4380.9024963 ,   409.15783381, 13189.6425703 ,  1679.15523363,\n",
       "        2713.14730186,  4568.29401632,  9068.79031226,  6535.43185726,\n",
       "        2320.14698468,  4492.33940817,   776.6433638 ,  1034.8465673 ,\n",
       "        4627.34304367,  1296.9833608 ,   500.84877221,  2916.80614448,\n",
       "         593.43667082,   544.89213503,  7099.16720474,  3116.65740998,\n",
       "         184.64037536,  1405.53478077,  2975.94343816,  1741.97565164,\n",
       "       10929.27488608,  2731.66507344,   107.06234189,  4740.3803971 ,\n",
       "        4750.55906598,  1179.83131143,  -904.14788506,  1975.07509982,\n",
       "        3074.66814315,  3964.62675579,  2404.7442677 ,  2525.55888361,\n",
       "         373.89287129,  2655.0306558 ,    60.52549899,  1908.14256679,\n",
       "         376.53284704,  7692.12337141,    55.29798827,  1306.78821581,\n",
       "         695.11489889, 16296.76392222,  5085.21299475,   -27.75460327,\n",
       "        2492.65161399,  1197.89285381,  3027.17624838,  2341.62737188,\n",
       "         434.83847572,  1134.85341037,  -550.7203188 ,  7028.90198546,\n",
       "       20735.18997691,   878.96036396,  2499.77676317,  3060.59862738,\n",
       "        7223.31245745,  3473.82405543,  5574.14630288,  1747.98057854,\n",
       "        3514.99149455,  5250.26043538,  1557.97096733,  1965.88092055,\n",
       "         678.10364537,  3231.43710608,  2023.31673956,   551.10889281,\n",
       "        -440.09425609,  3667.99786157,  8393.78384092,  2681.90346139,\n",
       "        5757.83655822,  -188.49973128,   906.24129744,  3457.14038184,\n",
       "         273.26126553,  2145.00161276,  5554.57413113,   287.07214508,\n",
       "        1805.84424681,  4573.69650157,   300.31753972,  -427.76292906,\n",
       "        3340.5094829 ,  2232.64485609,  7697.80335011, 11140.01777404,\n",
       "         -22.8505124 ,  -151.94366311,   727.01082177,  7203.52952691,\n",
       "        5557.97824384,  -713.2976126 ,  1302.93415676,  2475.02483229,\n",
       "        1948.48853131,   309.77538753,  1588.42928463,  1999.1094344 ,\n",
       "        4920.62203968,   138.98395939,  3930.91833014,  4295.45123831,\n",
       "        2833.63192693,   252.29743333,  6640.87840254,  1759.83372153,\n",
       "       10600.76728221,  2200.28981552,  7396.78235287,  2947.26201585,\n",
       "        1235.30508684, 11810.38070451,  4032.01120349, 13569.39897916,\n",
       "         -93.29648832,  4376.78436922,  6981.69747546,  1029.37001596,\n",
       "        2569.83470912,  4245.5767296 ,   622.38100355,  9425.9235509 ,\n",
       "       11504.40937479,  2498.8215962 ,  3626.98272572,  5058.23480658,\n",
       "        2297.95010104,  2730.09634689,  1650.90408376,  1583.66605022])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predicting on the testing dataset\n",
    "lm_preds = lm_md.predict(X_test)\n",
    "lm_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "868c2c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the Linear Regression Model is 2950422.714033583\n"
     ]
    }
   ],
   "source": [
    "## calculating the MSE for this model\n",
    "mse1 = np.mean((Y_test - lm_preds)**2)\n",
    "print('The MSE of the Linear Regression Model is', mse1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635908d",
   "metadata": {},
   "source": [
    "## building ridge regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b30a8ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal lambda for the ridge model is 0.001\n",
      "The optimal lambda for the lasso model is 2.0417959183673466\n"
     ]
    }
   ],
   "source": [
    "## estimating the best lambda for ridge model (1st) and LASSO model (2nd)\n",
    "ridge_cv = RidgeCV(alphas = np.linspace(0.001, 100), cv = 5).fit(X_train, Y_train)\n",
    "lasso_cv = LassoCV(alphas = np.linspace(0.001, 100), normalize = True, cv = 5).fit(X_train, Y_train)\n",
    "\n",
    "## extracting the best lambda value for both models\n",
    "CV_lambda = ridge_cv.alpha_\n",
    "cv_lambda = lasso_cv.alpha_\n",
    "print('The optimal lambda for the ridge model is', CV_lambda)\n",
    "print('The optimal lambda for the lasso model is', cv_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "754e8613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the Linear Regression Model is 2950422.714033583\n",
      "The MSE of the Ridge Regression Model is 2950505.5710513885\n",
      "The MSE of the LASSO Regression Model is 2974561.7142281863\n"
     ]
    }
   ],
   "source": [
    "## building the ridge model\n",
    "ridge_md = Ridge(alpha = CV_lambda).fit(X_train, Y_train)\n",
    "\n",
    "## building the lasso model and capturing coefficients\n",
    "lasso_md = Lasso(alpha = cv_lambda, normalize = True).fit(X_train, Y_train)\n",
    "lasso_md.coef_\n",
    "              \n",
    "## predicting on the testing dataset for the ridge model\n",
    "ridge_pred = ridge_md.predict(X_test)\n",
    "lasso_pred = lasso_md.predict(X_test)\n",
    "\n",
    "## computing the MSE of both models\n",
    "mse2 = np.mean(np.power(Y_test - ridge_pred, 2))\n",
    "mse3 = np.mean(np.power(Y_test - lasso_pred, 2))\n",
    "\n",
    "## printing MSE results\n",
    "print('The MSE of the Linear Regression Model is', mse1)\n",
    "print('The MSE of the Ridge Regression Model is', mse2)\n",
    "print('The MSE of the LASSO Regression Model is', mse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc9664e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse1<mse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5dca4b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse1<mse3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7a77f",
   "metadata": {},
   "source": [
    "Based on these MSE values, I would choose the Linear Regression model because it has the lowest MSE value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
