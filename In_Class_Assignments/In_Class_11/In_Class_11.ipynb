{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddfe0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ID</th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>carlength</th>\n",
       "      <th>carwidth</th>\n",
       "      <th>carheight</th>\n",
       "      <th>curbweight</th>\n",
       "      <th>enginetype</th>\n",
       "      <th>cylindernumber</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero giulia</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero stelvio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>64.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>2548</td>\n",
       "      <td>dohc</td>\n",
       "      <td>four</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>alfa-romero Quadrifoglio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>52.4</td>\n",
       "      <td>2823</td>\n",
       "      <td>ohcv</td>\n",
       "      <td>six</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100 ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>ohc</td>\n",
       "      <td>five</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   car_ID  symboling                   CarName fueltype aspiration doornumber  \\\n",
       "0       1          3        alfa-romero giulia      gas        std        two   \n",
       "1       2          3       alfa-romero stelvio      gas        std        two   \n",
       "2       3          1  alfa-romero Quadrifoglio      gas        std        two   \n",
       "3       4          2               audi 100 ls      gas        std       four   \n",
       "4       5          2                audi 100ls      gas        std       four   \n",
       "\n",
       "       carbody drivewheel enginelocation  wheelbase  carlength  carwidth  \\\n",
       "0  convertible        rwd          front       88.6      168.8      64.1   \n",
       "1  convertible        rwd          front       88.6      168.8      64.1   \n",
       "2    hatchback        rwd          front       94.5      171.2      65.5   \n",
       "3        sedan        fwd          front       99.8      176.6      66.2   \n",
       "4        sedan        4wd          front       99.4      176.6      66.4   \n",
       "\n",
       "   carheight  curbweight enginetype cylindernumber  enginesize fuelsystem  \\\n",
       "0       48.8        2548       dohc           four         130       mpfi   \n",
       "1       48.8        2548       dohc           four         130       mpfi   \n",
       "2       52.4        2823       ohcv            six         152       mpfi   \n",
       "3       54.3        2337        ohc           four         109       mpfi   \n",
       "4       54.3        2824        ohc           five         136       mpfi   \n",
       "\n",
       "   boreratio  stroke  compressionratio  horsepower  peakrpm  citympg  \\\n",
       "0       3.47    2.68               9.0         111     5000       21   \n",
       "1       3.47    2.68               9.0         111     5000       21   \n",
       "2       2.68    3.47               9.0         154     5000       19   \n",
       "3       3.19    3.40              10.0         102     5500       24   \n",
       "4       3.19    3.40               8.0         115     5500       18   \n",
       "\n",
       "   highwaympg    price  \n",
       "0          27  13495.0  \n",
       "1          27  16500.0  \n",
       "2          26  16500.0  \n",
       "3          30  13950.0  \n",
       "4          22  17450.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_column', 100)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "## define bucket in which you are trying to reach from Amazon S3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'daltondencklau-data445-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## define csv file to read in the bucket\n",
    "file_key= 'CarPrice_Assignment.csv'\n",
    "\n",
    "## syntax to allow us to read the file\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## reading the data file\n",
    "car_price = pd.read_csv(file_content_stream)\n",
    "car_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4f8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining input and target variables\n",
    "X = car_price[['wheelbase', 'enginesize', 'compressionratio', 'horsepower', 'peakrpm', 'citympg']]\n",
    "Y = car_price['price']\n",
    "\n",
    "## splitting the data into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51426de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## min max scaler transformation (standardizing data bc Neural Networks are sensitive to inputs)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f9492",
   "metadata": {},
   "source": [
    "## First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d40a827",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 216285616.0000 - val_loss: 333799200.0000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216285088.0000 - val_loss: 333798432.0000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216284528.0000 - val_loss: 333797696.0000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 216283968.0000 - val_loss: 333796992.0000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 216283408.0000 - val_loss: 333796192.0000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216282880.0000 - val_loss: 333795488.0000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216282336.0000 - val_loss: 333794784.0000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216281760.0000 - val_loss: 333794016.0000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 216281184.0000 - val_loss: 333793280.0000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 216280640.0000 - val_loss: 333792576.0000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 216280096.0000 - val_loss: 333791872.0000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 216279520.0000 - val_loss: 333791072.0000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216278944.0000 - val_loss: 333790336.0000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216278384.0000 - val_loss: 333789632.0000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216277840.0000 - val_loss: 333788864.0000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216277296.0000 - val_loss: 333788096.0000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216276720.0000 - val_loss: 333787328.0000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216276160.0000 - val_loss: 333786592.0000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216275600.0000 - val_loss: 333785856.0000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216275072.0000 - val_loss: 333785088.0000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 216274512.0000 - val_loss: 333784352.0000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216273952.0000 - val_loss: 333783616.0000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216273392.0000 - val_loss: 333782848.0000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216272848.0000 - val_loss: 333782080.0000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216272272.0000 - val_loss: 333781344.0000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216271744.0000 - val_loss: 333780576.0000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216271200.0000 - val_loss: 333779808.0000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216270656.0000 - val_loss: 333779072.0000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216270096.0000 - val_loss: 333778304.0000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216269552.0000 - val_loss: 333777536.0000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216268992.0000 - val_loss: 333776800.0000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216268448.0000 - val_loss: 333776032.0000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216267904.0000 - val_loss: 333775232.0000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 216267344.0000 - val_loss: 333774528.0000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216266752.0000 - val_loss: 333773728.0000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216266208.0000 - val_loss: 333772960.0000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216265648.0000 - val_loss: 333772192.0000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216265056.0000 - val_loss: 333771456.0000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216264512.0000 - val_loss: 333770688.0000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 216263952.0000 - val_loss: 333769888.0000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 216263360.0000 - val_loss: 333769088.0000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 216262800.0000 - val_loss: 333768352.0000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216262208.0000 - val_loss: 333767552.0000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216261600.0000 - val_loss: 333766784.0000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216261056.0000 - val_loss: 333765952.0000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 216260464.0000 - val_loss: 333765152.0000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216259856.0000 - val_loss: 333764320.0000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216259280.0000 - val_loss: 333763584.0000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 216258656.0000 - val_loss: 333762720.0000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 216258064.0000 - val_loss: 333761888.0000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216257456.0000 - val_loss: 333761056.0000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216256864.0000 - val_loss: 333760224.0000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216256208.0000 - val_loss: 333759424.0000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216255616.0000 - val_loss: 333758528.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216254960.0000 - val_loss: 333757696.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216254320.0000 - val_loss: 333756800.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216253664.0000 - val_loss: 333755936.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216253008.0000 - val_loss: 333755104.0000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216252368.0000 - val_loss: 333754176.0000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216251664.0000 - val_loss: 333753280.0000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 216251024.0000 - val_loss: 333752384.0000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216250320.0000 - val_loss: 333751456.0000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216249616.0000 - val_loss: 333750560.0000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216248912.0000 - val_loss: 333749632.0000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216248224.0000 - val_loss: 333748672.0000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216247488.0000 - val_loss: 333747744.0000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 216246800.0000 - val_loss: 333746816.0000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 216246048.0000 - val_loss: 333745824.0000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 216245328.0000 - val_loss: 333744864.0000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216244592.0000 - val_loss: 333743904.0000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 216243856.0000 - val_loss: 333742912.0000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216243120.0000 - val_loss: 333741920.0000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 216242352.0000 - val_loss: 333740960.0000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216241600.0000 - val_loss: 333739904.0000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216240800.0000 - val_loss: 333738912.0000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216240032.0000 - val_loss: 333737888.0000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216239280.0000 - val_loss: 333736896.0000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 216238480.0000 - val_loss: 333735872.0000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216237728.0000 - val_loss: 333734848.0000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216236928.0000 - val_loss: 333733760.0000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216236112.0000 - val_loss: 333732736.0000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216235328.0000 - val_loss: 333731680.0000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216234512.0000 - val_loss: 333730656.0000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216233680.0000 - val_loss: 333729600.0000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216232832.0000 - val_loss: 333728480.0000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216232032.0000 - val_loss: 333727392.0000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216231184.0000 - val_loss: 333726304.0000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216230336.0000 - val_loss: 333725152.0000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216229488.0000 - val_loss: 333724032.0000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216228608.0000 - val_loss: 333722912.0000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216227808.0000 - val_loss: 333721760.0000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216226912.0000 - val_loss: 333720640.0000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216226048.0000 - val_loss: 333719488.0000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216225136.0000 - val_loss: 333718336.0000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216224288.0000 - val_loss: 333717152.0000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216223392.0000 - val_loss: 333716000.0000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216222464.0000 - val_loss: 333714816.0000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216221600.0000 - val_loss: 333713696.0000\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216220640.0000 - val_loss: 333712448.0000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216219776.0000 - val_loss: 333711232.0000\n"
     ]
    }
   ],
   "source": [
    "## defining the model (NN) with one layer\n",
    "md1 = tf.keras.models.Sequential([\n",
    "    \n",
    "    ## defining the one layer with (10 neurons, 6 input varaibles, and activation function)\n",
    "    tf.keras.layers.Dense(10, input_dim = 6, activation = 'relu'),\n",
    "    \n",
    "    ## defining how many layers\n",
    "    tf.keras.layers.Dense(1)\n",
    "\n",
    "])\n",
    "\n",
    "## defining how model will be estimated (optimizer = 'algorithm to estimate weights', loss = 'measure of how I want model to be estimated')\n",
    "md1.compile(optimizer = 'adam', loss = 'mse')\n",
    "## loss = MSE \n",
    "history = md1.fit(X_train, Y_train, epochs = 100, batch_size = 100, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd300864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 333736672.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "333736672.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## making predictions on test data set (comparing predictions and actual values)\n",
    "md1.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "407a101e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHrCAYAAADmAqpvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfYUlEQVR4nO3de5Scd33f8c83kiwBMnErROpYODIpJVziS9iExG6LjUmBBAq9UEiBEi7HB5pSSKA4kCaB0J6StIXWTYmPCxQoHJIUTHFJoTGpXUMNdiXigI24ndgBBRsLJb6QBMeXb//YgWzFrqSfPM+utXq9zlk088xvnvnuPtr1W8OzM9XdAQAADs93rPUAAABwNBHQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAw4KgM6Kp6W1XdXFXXHsbak6vqsqr63ar6VFX92GrMCADA+nRUBnSStyd50mGu/edJfrO7z0jyrCRvnmooAADWv6MyoLv7iiR/tHRbVX1vVX24qnZX1Uer6vu+uTzJA2eXvzPJV1ZxVAAA1pmNaz3AHF2U5MXd/YWqemwWn2l+fJLXJvntqnppkgckecLajQgAwNFuXQR0VW1NcmaS/1pV39y8efbnTyR5e3f/26r6kST/paoe3d33rMGoAAAc5dZFQGfxVJRbuvv0ZW57YWbnS3f3x6tqS5IHJbl59cYDAGC9OCrPgT5Qd9+W5PqqekaS1KLTZjd/Kcm5s+2PSLIlyb41GRQAgKNedfdazzCsqt6T5OwsPpP81SS/mOR/Jfm1JCcm2ZTk17v7l6rqkUn+U5KtWfyFwld192+vxdwAABz9jsqABgCAtbIuTuEAAIDVIqABAGDAUfcqHA960IN6586daz0GAADr3O7du7/W3dsP3H7UBfTOnTuza9eutR4DAIB1rqr+YLntTuEAAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBgwMa1HuCocM89yR23rXx71RHsdIX7DO9rcP2K+z+Cz2Fe+7ovfv3meRxG93VEXw8AYLUI6MNx+1eSNz1qraeAQfP6x8E897UKM624fDX+wXdf+zod7B92g7sanmk9fF3n+A/jeT32XJ8EGbxhTWed+LHn+ndgXjOt+MBrONO81h/BfZ75rmTrgw+yv9UloA/Hlu9MnvivVrixx/fXK91ncF8r7mfFO8xpP/Pc11p+/YZvWGH5wdbPa19rtJ957mtVZlrxDtPu54j2Nbqfo+jv5ap8Xdfyc5j6sQcfd1V+hk+9/mDui7PO6fNb05nWaP2R3udI/uE1IQF9ODYfn/zIP17rKQAAuA/wS4QAADBAQAMAwAABDQAAAwQ0AAAMENAAADBAQAMAwAABDQAAAwQ0AAAMENAAADBAQAMAwAABDQAAAwQ0AAAMENAAADBAQAMAwAABDQAAAwQ0AAAMENAAADBAQAMAwAABDQAAAwQ0AAAMENAAADBAQAMAwAABDQAAAwQ0AAAMENAAADBAQAMAwAABDQAAAwQ0AAAMENAAADBAQAMAwAABDQAAAwQ0AAAMENAAADBAQAMAwAABDQAAAwQ0AAAMENAAADBAQAMAwAABDQAAAwQ0AAAMmCygq2pLVV1dVb9XVddV1euWWfPsqvrU7OPKqjptqnkAAGAeNk647zuSPL67v15Vm5J8rKo+1N2fWLLm+iSP6+4/rqonJ7koyWMnnAkAAO6VyQK6uzvJ12dXN80++oA1Vy65+okkO6aaBwAA5mHSc6CrakNVXZPk5iSXdvdVB1n+wiQfmnIeAAC4tyYN6O6+u7tPz+Izyz9UVY9ebl1VnZPFgD5/hdvPq6pdVbVr3759k80LAACHsiqvwtHdtyS5PMmTDrytqk5N8pYkT+vu/Svc/6LuXujuhe3bt085KgAAHNSUr8KxvapOmF2+X5InJPnsAWtOTnJxkud29+enmgUAAOZlylfhODHJO6pqQxZD/Te7+4NV9eIk6e4Lk/xCkm1J3lxVSXJXdy9MOBMAANwrU74Kx6eSnLHM9guXXH5RkhdNNQMAAMybdyIEAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGDBZQFfVlqq6uqp+r6quq6rXLbOmquqCqvpiVX2qqn5gqnkAAGAeNk647zuSPL67v15Vm5J8rKo+1N2fWLLmyUkeNvt4bJJfm/0JAAD3SZM9A92Lvj67umn20Qcse1qSd87WfiLJCVV14lQzAQDAvTXpOdBVtaGqrklyc5JLu/uqA5aclOTLS67vnW07cD/nVdWuqtq1b9++yeYFAIBDmTSgu/vu7j49yY4kP1RVjz5gSS13t2X2c1F3L3T3wvbt2yeYFAAADs+qvApHd9+S5PIkTzrgpr1JHrLk+o4kX1mNmQAA4EhM+Soc26vqhNnl+yV5QpLPHrDskiT/aPZqHD+c5NbuvnGqmQAA4N6a8lU4TkzyjqrakMVQ/83u/mBVvThJuvvCJP8jyY8l+WKSP03y/AnnAQCAe22ygO7uTyU5Y5ntFy653El+aqoZAABg3rwTIQAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwYLKArqqHVNVlVbWnqq6rqpcts+Y7q+q/V9XvzdY8f6p5AABgHjZOuO+7kryiuz9ZVccn2V1Vl3b3Z5as+akkn+nup1bV9iSfq6p3d/efTzgXAAAcscmege7uG7v7k7PLtyfZk+SkA5clOb6qKsnWJH+UxfAGAID7pCmfgf6WqtqZ5IwkVx1w068muSTJV5Icn+SZ3X3PaswEAABHYvKArqqtSd6X5OXdfdsBNz8xyTVJHp/ke5NcWlUfPXBdVZ2X5LwkOfnkk6ceGQDgmHfnnXdm7969+cY3vrHWo0xuy5Yt2bFjRzZt2nRY6ycN6KralMV4fnd3X7zMkucneUN3d5IvVtX1Sb4vydVLF3X3RUkuSpKFhYWecmYAAJK9e/fm+OOPz86dO7N4tu361N3Zv39/9u7dm1NOOeWw7jPlq3BUkrcm2dPdb1xh2ZeSnDtb/11JHp7k96eaCQCAw/ONb3wj27ZtW9fxnCRVlW3btg090z7lM9BnJXlukk9X1TWzba9JcnKSdPeFSV6f5O1V9ekkleT87v7ahDMBAHCY1ns8f9Po5zlZQHf3x7IYxQdb85Ukf2uqGQAAODrt378/5557bpLkpptuyoYNG7J9+/YkydVXX53jjjtuxfvu2rUr73znO3PBBRdMMtuqvAoHAACM2LZtW6655pokyWtf+9ps3bo1r3zlK791+1133ZWNG5dP2YWFhSwsLEw2m7fyBgDgqPCTP/mT+Zmf+Zmcc845Of/883P11VfnzDPPzBlnnJEzzzwzn/vc55Ikl19+eZ7ylKckWYzvF7zgBTn77LPz0Ic+dC7PSnsGGgCAg3rdf78un/nKga9GfO888rsfmF986qOG7/f5z38+H/nIR7Jhw4bcdtttueKKK7Jx48Z85CMfyWte85q8733v+7b7fPazn81ll12W22+/PQ9/+MPzkpe85LBfsm45Bw3oqnpOd79rdvms7v4/S277J939q0f8yAAAMOgZz3hGNmzYkCS59dZb87znPS9f+MIXUlW58847l73Pj//4j2fz5s3ZvHlzHvzgB+erX/1qduzYccQzHOoZ6J9J8q7Z5f+Q5AeW3PaCLL6TIAAA69iRPFM8lQc84AHfuvzzP//zOeecc/L+978/N9xwQ84+++xl77N58+ZvXd6wYUPuuuuuezXDoc6BrhUuL3cdAABWza233pqTTjopSfL2t7991R73UAHdK1xe7joAAKyaV73qVXn1q1+ds846K3ffffeqPW4tvov2CjdW/WmSL2bx2ebvnV3O7PpDu/sBK913KgsLC71r167VflgAgGPKnj178ohHPGKtx1g1y32+VbW7u7/t9fAOdQ70sfNVAwCAw3DQgO7uP1h6vaq2JfmbSb7U3bunHAwAAO6LDnoOdFV9sKoePbt8YpJrs/jqG/+lql4+/XgAAHDfcqhfIjylu6+dXX5+kku7+6lJHpvFkAYAgGPKoQJ66atRn5vkfyRJd9+e5J6phgIAgPuqQ/0S4Zer6qVJ9mbxTVQ+nCRVdb8kR/7+hwAAcJQ6VEC/MMkvJXlCkmd29y2z7T+c5D9POBcAAMew/fv359xzz02S3HTTTdmwYUO2b9+eJLn66qtz3HHHHfT+l19+eY477riceeaZc5/tUK/CcXOSFy+z/bIkl819GgAASLJt27Zcc801SZLXvva12bp1a175ylce9v0vv/zybN26dZKAPtSrcFxysI+5TwMAACvYvXt3Hve4x+Uxj3lMnvjEJ+bGG29MklxwwQV55CMfmVNPPTXPetazcsMNN+TCCy/Mm970ppx++un56Ec/Otc5DnUKx48k+XKS9yS5KovvQAgAwLHkQz+b3PTp+e7zr3x/8uQ3HPby7s5LX/rSfOADH8j27dvzG7/xG/m5n/u5vO1tb8sb3vCGXH/99dm8eXNuueWWnHDCCXnxi188/Kz14TpUQP+VJD+a5CeS/MMkv5XkPd193dwnAQCAFdxxxx259tpr86M/+qNJkrvvvjsnnnhikuTUU0/Ns5/97Dz96U/P05/+9MlnOdQ50Hdn8ZU3PlxVm7MY0pdX1S9193+YfDoAANbewDPFU+nuPOpRj8rHP/7xb7vtt37rt3LFFVfkkksuyetf//pcd920z/Ue6nWgU1Wbq+rvJnlXkp9KckGSiyedCgAAlti8eXP27dv3rYC+8847c9111+Wee+7Jl7/85Zxzzjn5lV/5ldxyyy35+te/nuOPPz633377JLMc6pcI35Hkyiy+BvTruvsHu/v13f2Hk0wDAADL+I7v+I68973vzfnnn5/TTjstp59+eq688srcfffdec5znpPv//7vzxlnnJGf/umfzgknnJCnPvWpef/73z/JLxFWd698Y9U9Sf5kdnXpwkrS3f3AuU5zGBYWFnrXrl2r/bAAAMeUPXv25BGPeMRaj7Fqlvt8q2p3dy8cuPZQ50Af8hQPAAA4lghkAAAYIKABAGCAgAYAYFkH+1259WT08xTQAAB8my1btmT//v3rPqK7O/v378+WLVsO+z6HeidCAACOQTt27MjevXuzb9++tR5lclu2bMmOHTsOe72ABgDg22zatCmnnHLKWo9xn+QUDgAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAZMFtBV9ZCquqyq9lTVdVX1shXWnV1V18zW/O+p5gEAgHnYOOG+70ryiu7+ZFUdn2R3VV3a3Z/55oKqOiHJm5M8qbu/VFUPnnAeAAC41yZ7Brq7b+zuT84u355kT5KTDlj2D5Nc3N1fmq27eap5AABgHlblHOiq2pnkjCRXHXDTX0vyl6rq8qraXVX/aDXmAQCAIzXlKRxJkqramuR9SV7e3bct8/iPSXJukvsl+XhVfaK7P3/APs5Lcl6SnHzyyVOPDAAAK5r0Geiq2pTFeH53d1+8zJK9ST7c3X/S3V9LckWS0w5c1N0XdfdCdy9s3759ypEBAOCgpnwVjkry1iR7uvuNKyz7QJK/UVUbq+r+SR6bxXOlAQDgPmnKUzjOSvLcJJ+uqmtm216T5OQk6e4Lu3tPVX04yaeS3JPkLd197YQzAQDAvTJZQHf3x5LUYaz710n+9VRzAADAPHknQgAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBgwGQBXVUPqarLqmpPVV1XVS87yNofrKq7q+rvTzUPAADMw8YJ931Xkld09yer6vgku6vq0u7+zNJFVbUhyS8n+Z8TzgIAAHMx2TPQ3X1jd39ydvn2JHuSnLTM0pcmeV+Sm6eaBQAA5mVVzoGuqp1Jzkhy1QHbT0ryd5JcuBpzAADAvTV5QFfV1iw+w/zy7r7tgJv/XZLzu/vuQ+zjvKraVVW79u3bN9GkAABwaNXd0+28alOSDyb5n939xmVuvz5Jza4+KMmfJjmvu//bSvtcWFjoXbt2TTAtAAD8hara3d0LB26f7JcIq6qSvDXJnuXiOUm6+5Ql69+e5IMHi2cAAFhrU74Kx1lJnpvk01V1zWzba5KcnCTd7bxnAACOOpMFdHd/LH9xesbhrP/JqWYBAIB58U6EAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMENAAADBDQAAAwQEADAMAAAQ0AAAMmC+iqekhVXVZVe6rquqp62TJrnl1Vn5p9XFlVp001DwAAzMPGCfd9V5JXdPcnq+r4JLur6tLu/sySNdcneVx3/3FVPTnJRUkeO+FMAABwr0wW0N19Y5IbZ5dvr6o9SU5K8pkla65ccpdPJNkx1TwAADAPq3IOdFXtTHJGkqsOsuyFST60wv3Pq6pdVbVr3759E0wIAACHZ/KArqqtSd6X5OXdfdsKa87JYkCfv9zt3X1Rdy9098L27dunGxYAAA5hynOgU1WbshjP7+7ui1dYc2qStyR5cnfvn3IeAAC4t6Z8FY5K8tYke7r7jSusOTnJxUme292fn2oWAACYlymfgT4ryXOTfLqqrplte02Sk5Okuy9M8gtJtiV582Jv567uXphwJgAAuFemfBWOjyWpQ6x5UZIXTTUDAADMm3ciBACAAQIaAAAGCGgAABggoAEAYICABgCAAQIaAAAGTPpOhOvFjbf+Wf7Wm64Yvt9BX8NvpfvU2L0Glx/RTCs/9uCsw/sfvMMRPMpqfP3GH+O+9zms/Njz3Nty+5/+PlN/vRcfY3D9xN9bR3KnlZavxqz3xWO68r6W39nUP/8Otn5eX4/hL9OcvhYH2dXcvrfmO9N8hl35e25sP4v7WuHzXmnUOX3PHdnP8OXv9KZ/cFq2bd08vsOJCOjDcP9NG/P3H7Nj6D7dEw3z/z3G2IPMc6TRz68HH/1Ivn6jdxl/jPGhhr9O98Gv68qPPbh+4s9tdqcplw9/zx3ZY0y7/8XHmNPPjlU4pmv1PTTPn0FT/6w52P7n9Xd8Xn+PV+Pv68r7WWH7HP9ezusxDvb1G/5y9Lf+57BmmtfPoIMdtyP5XrlnFbpqhIA+DN95/035xac+aq3HAADgPsA50AAAMEBAAwDAAAENAAADBDQAAAwQ0AAAMEBAAwDAAAENAAADBDQAAAwQ0AAAMEBAAwDAAAENAAADBDQAAAwQ0AAAMEBAAwDAAAENAAADBDQAAAwQ0AAAMEBAAwDAgOrutZ5hSFXtS/IHa/TwD0rytTV6bFaXY33scKyPHY71scOxPnZMfay/p7u3H7jxqAvotVRVu7p7Ya3nYHqO9bHDsT52ONbHDsf62LFWx9opHAAAMEBAAwDAAAE95qK1HoBV41gfOxzrY4djfexwrI8da3KsnQMNAAADPAMNAAADBPRhqKonVdXnquqLVfWzaz0P81NVD6mqy6pqT1VdV1Uvm23/y1V1aVV9YfbnX1rrWZmPqtpQVb9bVR+cXXes16GqOqGq3ltVn519f/+IY70+VdVPz35+X1tV76mqLY71+lBVb6uqm6vq2iXbVjy2VfXqWat9rqqeOOVsAvoQqmpDkv+Y5MlJHpnkJ6rqkWs7FXN0V5JXdPcjkvxwkp+aHd+fTfI73f2wJL8zu8768LIke5Zcd6zXp3+f5MPd/X1JTsviMXes15mqOinJP02y0N2PTrIhybPiWK8Xb0/ypAO2LXtsZ//tflaSR83u8+ZZw01CQB/aDyX5Ynf/fnf/eZJfT/K0NZ6JOenuG7v7k7PLt2fxP7InZfEYv2O27B1Jnr4mAzJXVbUjyY8necuSzY71OlNVD0zyN5O8NUm6+8+7+5Y41uvVxiT3q6qNSe6f5CtxrNeF7r4iyR8dsHmlY/u0JL/e3Xd09/VJvpjFhpuEgD60k5J8ecn1vbNtrDNVtTPJGUmuSvJd3X1jshjZSR68hqMxP/8uyauS3LNkm2O9/jw0yb4k/3l2us5bquoBcazXne7+wyT/JsmXktyY5Nbu/u041uvZSsd2VXtNQB9aLbPNS5esM1W1Ncn7kry8u29b63mYv6p6SpKbu3v3Ws/C5DYm+YEkv9bdZyT5k/i/8Nel2fmvT0tySpLvTvKAqnrO2k7FGlnVXhPQh7Y3yUOWXN+Rxf97iHWiqjZlMZ7f3d0XzzZ/tapOnN1+YpKb12o+5uasJH+7qm7I4qlYj6+qd8WxXo/2Jtnb3VfNrr83i0HtWK8/T0hyfXfv6+47k1yc5Mw41uvZSsd2VXtNQB/a/03ysKo6paqOy+IJ6pes8UzMSVVVFs+T3NPdb1xy0yVJnje7/LwkH1jt2Ziv7n51d+/o7p1Z/D7+X939nDjW605335Tky1X18Nmmc5N8Jo71evSlJD9cVfef/Tw/N4u/y+JYr18rHdtLkjyrqjZX1SlJHpbk6qmG8EYqh6GqfiyL505uSPK27v6XazsR81JVfz3JR5N8On9xXuxrsnge9G8mOTmLP6Cf0d0H/iIDR6mqOjvJK7v7KVW1LY71ulNVp2fxl0WPS/L7SZ6fxSeNHOt1pqpel+SZWXxVpd9N8qIkW+NYH/Wq6j1Jzk7yoCRfTfKLSf5bVji2VfVzSV6Qxb8LL+/uD002m4AGAIDD5xQOAAAYIKABAGCAgAYAgAECGgAABghoAAAYIKABjiJVdXdVXbPkY27vsFdVO6vq2nntD2C92rjWAwAw5M+6+/S1HgLgWOYZaIB1oKpuqKpfrqqrZx9/dbb9e6rqd6rqU7M/T55t/66qen9V/d7s48zZrjZU1X+qquuq6rer6n5r9kkB3EcJaICjy/0OOIXjmUtuu627fyjJr2bx3VMzu/zO7j41ybuTXDDbfkGS/93dpyX5gSTXzbY/LMl/7O5HJbklyd+b9LMBOAp5J0KAo0hVfb27ty6z/YYkj+/u36+qTUlu6u5tVfW1JCd2952z7Td294Oqal+SHd19x5J97ExyaXc/bHb9/CSbuvtfrMKnBnDU8Aw0wPrRK1xeac1y7lhy+e74XRmAbyOgAdaPZy758+Ozy1cmedbs8rOTfGx2+XeSvCRJqmpDVT1wtYYEONp5ZgHg6HK/qrpmyfUPd/c3X8puc1VdlcUnR35itu2fJnlbVf2zJPuSPH+2/WVJLqqqF2bxmeaXJLlx6uEB1gPnQAOsA7NzoBe6+2trPQvAeucUDgAAGOAZaAAAGOAZaAAAGCCgAQBggIAGAIABAhoAAAYIaAAAGCCgAQBgwP8DqjmVvAu5jOMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386f33b",
   "metadata": {},
   "source": [
    "The model is overfitting the data because the model is preforing well only on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d80e8",
   "metadata": {},
   "source": [
    "## Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a18fbb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 216280144.0000 - val_loss: 333793344.0000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 216279920.0000 - val_loss: 333793120.0000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 216279712.0000 - val_loss: 333792896.0000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216279520.0000 - val_loss: 333792704.0000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 216279296.0000 - val_loss: 333792480.0000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 216279088.0000 - val_loss: 333792288.0000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 216278864.0000 - val_loss: 333792064.0000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216278640.0000 - val_loss: 333791808.0000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 216278384.0000 - val_loss: 333791520.0000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 216278096.0000 - val_loss: 333791296.0000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216277760.0000 - val_loss: 333790976.0000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 216277440.0000 - val_loss: 333790688.0000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216277088.0000 - val_loss: 333790336.0000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216276736.0000 - val_loss: 333789984.0000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216276368.0000 - val_loss: 333789568.0000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216275936.0000 - val_loss: 333789120.0000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216275536.0000 - val_loss: 333788704.0000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216275072.0000 - val_loss: 333788224.0000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216274592.0000 - val_loss: 333787712.0000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216274112.0000 - val_loss: 333787200.0000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216273616.0000 - val_loss: 333786688.0000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216273088.0000 - val_loss: 333786112.0000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216272592.0000 - val_loss: 333785536.0000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216272016.0000 - val_loss: 333784928.0000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216271440.0000 - val_loss: 333784224.0000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216270816.0000 - val_loss: 333783488.0000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216270192.0000 - val_loss: 333782784.0000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216269600.0000 - val_loss: 333782048.0000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216268896.0000 - val_loss: 333781280.0000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216268224.0000 - val_loss: 333780480.0000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216267520.0000 - val_loss: 333779680.0000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216266832.0000 - val_loss: 333778880.0000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216266048.0000 - val_loss: 333777984.0000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216265280.0000 - val_loss: 333777056.0000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216264528.0000 - val_loss: 333776096.0000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216263728.0000 - val_loss: 333775104.0000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216262928.0000 - val_loss: 333774112.0000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216262064.0000 - val_loss: 333773056.0000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216261184.0000 - val_loss: 333772000.0000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216260304.0000 - val_loss: 333770880.0000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 216259408.0000 - val_loss: 333769728.0000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216258432.0000 - val_loss: 333768544.0000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216257504.0000 - val_loss: 333767360.0000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216256480.0000 - val_loss: 333766112.0000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216255520.0000 - val_loss: 333764832.0000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 216254464.0000 - val_loss: 333763520.0000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216253408.0000 - val_loss: 333762208.0000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216252288.0000 - val_loss: 333760896.0000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216251216.0000 - val_loss: 333759424.0000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216250064.0000 - val_loss: 333758016.0000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216248864.0000 - val_loss: 333756576.0000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216247664.0000 - val_loss: 333755072.0000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216246464.0000 - val_loss: 333753568.0000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216245216.0000 - val_loss: 333751968.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216243968.0000 - val_loss: 333750368.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216242624.0000 - val_loss: 333748736.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216241328.0000 - val_loss: 333747008.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216239952.0000 - val_loss: 333745312.0000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216238528.0000 - val_loss: 333743520.0000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216237136.0000 - val_loss: 333741760.0000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216235632.0000 - val_loss: 333739872.0000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216234160.0000 - val_loss: 333738048.0000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216232640.0000 - val_loss: 333736096.0000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216231056.0000 - val_loss: 333734144.0000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216229440.0000 - val_loss: 333732128.0000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216227840.0000 - val_loss: 333730080.0000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216226144.0000 - val_loss: 333727936.0000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216224416.0000 - val_loss: 333725792.0000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216222624.0000 - val_loss: 333723616.0000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216220848.0000 - val_loss: 333721376.0000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216219056.0000 - val_loss: 333719072.0000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216217152.0000 - val_loss: 333716704.0000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216215200.0000 - val_loss: 333714272.0000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216213280.0000 - val_loss: 333711872.0000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216211264.0000 - val_loss: 333709312.0000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216209152.0000 - val_loss: 333706752.0000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216207056.0000 - val_loss: 333704096.0000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216204864.0000 - val_loss: 333701376.0000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216202640.0000 - val_loss: 333698624.0000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 216200416.0000 - val_loss: 333695712.0000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216198016.0000 - val_loss: 333692832.0000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216195664.0000 - val_loss: 333689792.0000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 216193328.0000 - val_loss: 333686752.0000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 216190832.0000 - val_loss: 333683648.0000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216188224.0000 - val_loss: 333680480.0000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216185680.0000 - val_loss: 333677184.0000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216183088.0000 - val_loss: 333673952.0000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216180384.0000 - val_loss: 333670560.0000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 216177616.0000 - val_loss: 333667104.0000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216174848.0000 - val_loss: 333663616.0000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216172000.0000 - val_loss: 333660000.0000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216169072.0000 - val_loss: 333656384.0000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216166048.0000 - val_loss: 333652640.0000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 216163104.0000 - val_loss: 333648832.0000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216160000.0000 - val_loss: 333644960.0000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216156816.0000 - val_loss: 333640992.0000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 216153584.0000 - val_loss: 333636896.0000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216150320.0000 - val_loss: 333632800.0000\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 216146976.0000 - val_loss: 333628608.0000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 216143520.0000 - val_loss: 333624352.0000\n"
     ]
    }
   ],
   "source": [
    "## defining the model (NN) with 2 layer (10, then 8 neurons)\n",
    "md2 = tf.keras.models.Sequential([\n",
    "    \n",
    "    ## defining the one layer with (10 neurons, 6 input varaibles, and activation function)\n",
    "    tf.keras.layers.Dense(10, input_dim = 6, activation = 'relu'),\n",
    "    \n",
    "    ## defining the second layer with 8 layers\n",
    "    tf.keras.layers.Dense(8, input_dim = 6, activation = 'relu'),\n",
    "    \n",
    "    ## defining how many layers\n",
    "    tf.keras.layers.Dense(1)\n",
    "\n",
    "])\n",
    "\n",
    "## defining how model will be estimated (optimizer = 'algorithm to estimate weights', loss = 'measure of how I want model to be estimated')\n",
    "md2.compile(optimizer = 'adam', loss = 'mse')\n",
    "## loss = MSE \n",
    "history = md2.fit(X_train, Y_train, epochs = 100, batch_size = 100, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a53ea46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 333624352.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "333624352.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## making predictions on test data set (comparing predictions and actual values)\n",
    "md2.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a813ebe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(history2.history2['loss'])\n",
    "plt.plot(history2.history2['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f203a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2 has a smaller MSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
